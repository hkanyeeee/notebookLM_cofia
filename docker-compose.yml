version: "3.9"

networks:
  # 统一把所有相关容器放进同一个自定义网络
  localnet:
    name: localnet
    external: true  # 先手动创建：docker network create localnet

volumes:
  # qdrant_data:  # 如在 compose 内启用 qdrant，再打开

services:
  # -------------------
  # 可选：如你想把 Qdrant 也放进同一个 compose，就取消下面整段注释
  # -------------------
  # qdrant:
  #   image: qdrant/qdrant:latest
  #   container_name: qdrant
  #   restart: unless-stopped
  #   networks: [localnet]
  #   expose:
  #     - "6333"           # 供容器内访问，不对外暴露
  #   # 如需要从宿主或局域网访问，再映射端口
  #   # ports:
  #   #   - "6333:6333"
  #   # volumes:
  #   #   - qdrant_data:/qdrant/storage

  backend:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: notebooklm-backend
    environment:
      - DATABASE_URL=sqlite+aiosqlite:///data/app.db
      # 如果用容器里的 qdrant，默认用服务名；如仍用宿主机/外部的 qdrant，可通过 .env 覆盖 QDRANT_HOST
      - QDRANT_HOST=${QDRANT_HOST:-qdrant}
      - QDRANT_PORT=${QDRANT_PORT:-6333}
      # 代理（按需保留/删除）
      - PROXY_URL=${PROXY_URL:-http://192.168.31.167:7890}
      # 嵌入与大模型服务
      - EMBEDDING_SERVICE_URL=${EMBEDDING_SERVICE_URL:-http://embedding-gateway:7998/v1}
      - LLM_SERVICE_URL=${LLM_SERVICE_URL:-http://llm-gateway:7995/v1}
      - RERANKER_SERVICE_URL=${RERANKER_SERVICE_URL:-}
      - SEARXNG_QUERY_URL=${SEARXNG_QUERY_URL:-http://host.docker.internal:8080/search}
      
      # Qdrant 扩展配置
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      - QDRANT_COLLECTION_NAME=${QDRANT_COLLECTION_NAME:-notebooklm_prod}
      
      # 重排序和嵌入配置
      - RERANKER_MAX_TOKENS=${RERANKER_MAX_TOKENS:-8192}
      - RERANK_CLIENT_MAX_CONCURRENCY=${RERANK_CLIENT_MAX_CONCURRENCY:-4}
      - EMBEDDING_MAX_CONCURRENCY=${EMBEDDING_MAX_CONCURRENCY:-4}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-4}
      - EMBEDDING_DIMENSIONS=${EMBEDDING_DIMENSIONS:-1024}
      
      # 工具相关配置
      - DEFAULT_TOOL_MODE=${DEFAULT_TOOL_MODE:-auto}
      - MAX_TOOL_STEPS=${MAX_TOOL_STEPS:-8}
      
      # Web 搜索配置
      - WEB_SEARCH_RESULT_COUNT=${WEB_SEARCH_RESULT_COUNT:-2}
      - WEB_SEARCH_MAX_QUERIES=${WEB_SEARCH_MAX_QUERIES:-20}
      - WEB_SEARCH_MAX_RESULTS=${WEB_SEARCH_MAX_RESULTS:-40}
      - WEB_SEARCH_CONCURRENT_REQUESTS=${WEB_SEARCH_CONCURRENT_REQUESTS:-10}
      - WEB_SEARCH_TIMEOUT=${WEB_SEARCH_TIMEOUT:-10.0}
      - MAX_WORDS_PER_QUERY=${MAX_WORDS_PER_QUERY:-4}
      
      # 知识缺口和关键词配置
      - MAX_KEYWORDS_PER_GAP=${MAX_KEYWORDS_PER_GAP:-2}
      - GAP_RECALL_TOP_K=${GAP_RECALL_TOP_K:-4}
      
      # Web 爬取配置
      - WEB_LOADER_ENGINE=${WEB_LOADER_ENGINE:-safe_web}
      - PLAYWRIGHT_TIMEOUT=${PLAYWRIGHT_TIMEOUT:-10.0}
      
      # 查询生成配置
      - ENABLE_QUERY_GENERATION=${ENABLE_QUERY_GENERATION:-true}
      - QUERY_GENERATION_PROMPT_TEMPLATE=${QUERY_GENERATION_PROMPT_TEMPLATE:-}
      
      # Web 缓存配置
      - WEB_CACHE_ENABLED=${WEB_CACHE_ENABLED:-true}
      - WEB_CACHE_MAX_SIZE=${WEB_CACHE_MAX_SIZE:-1000}
      - WEB_CACHE_TTL_SECONDS=${WEB_CACHE_TTL_SECONDS:-3600}
      - WEB_CACHE_MAX_CONTENT_SIZE=${WEB_CACHE_MAX_CONTENT_SIZE:-1048576}
      
      # 文档处理配置
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-100}
      
      # RAG 配置
      - RAG_TOP_K=${RAG_TOP_K:-15}
      - QUERY_TOP_K_BEFORE_RERANK=${QUERY_TOP_K_BEFORE_RERANK:-200}
      - RAG_RERANK_TOP_K=${RAG_RERANK_TOP_K:-15}
      
      # LLM 配置
      - LLM_DEFAULT_TIMEOUT=${LLM_DEFAULT_TIMEOUT:-3600.0}
      - DEFAULT_SEARCH_MODEL=${DEFAULT_SEARCH_MODEL:-openai/gpt-oss-20b}
      - DEFAULT_INGEST_MODEL=${DEFAULT_INGEST_MODEL:-qwen3-coder-30b-a3b-instruct}
      - DEFAULT_EMBEDDING_MODEL=${DEFAULT_EMBEDDING_MODEL:-Qwen/Qwen3-Embedding-0.6B}
      
      # 推理引擎配置
      - REASONING_TIMEOUT=${REASONING_TIMEOUT:-3600.0}
      - WEB_SEARCH_LLM_TIMEOUT=${WEB_SEARCH_LLM_TIMEOUT:-1800.0}
    volumes:
      - ./data:/app/data
    depends_on:
      - embedding-gateway
      - llm-gateway
    networks:
      - localnet
    ports:
      - "8000:8000"   # 供宿主机访问；容器间仍可用服务名 backend:8000

  frontend:
    restart: always
    build:
      context: ./notebookLM_front
      dockerfile: Dockerfile
      args:
        NPM_REGISTRY: ${NPM_REGISTRY:-https://registry.npmjs.org}
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
    container_name: notebooklm-frontend
    ports:
      - "9001:80"
    depends_on:
      - backend
    networks:
      - localnet

  embedding-gateway:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: embedding-gateway
    ports:
      - "7998:7998"   # 如需从宿主/局域网调用保留；仅容器内互访其实不必映射
    command: ["python", "embedding_gateway.py"]
    environment:
      - EMBEDDING_BACKENDS=${EMBEDDING_BACKENDS:-http://192.168.31.98:7998/v1,http://192.168.31.231:7998/v1}
    networks:
      - localnet
    expose:
      - "7998"

  llm-gateway:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: llm-gateway
    ports:
      - "7995:7995"
    command: ["python", "llm_gateway.py"]
    environment:
      - LLM_BACKENDS=${LLM_BACKENDS:-http://192.168.31.98:1234/v1,http://192.168.31.231:1234/v1}
      - LLM_GATEWAY_HOST=0.0.0.0
      - LLM_GATEWAY_PORT=7995
      - LLM_TIMEOUT=${LLM_TIMEOUT:-600}
    networks:
      - localnet
    expose:
      - "7995"
